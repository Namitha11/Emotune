# Emotune
AI Based music recommendation system using facial expressions
This project demonstrates an AI-driven music recommendation system that tailors music suggestions based on the user's facial expressions. By leveraging computer vision and emotion recognition techniques, the system analyzes real-time facial expressions to infer the user's current emotional state and recommends music tracks that match or enhance their mood.

Key Features:
Real-Time Facial Expression Detection: The system uses deep learning models to detect and interpret facial expressions, categorizing them into emotions such as happiness, sadness, anger, surprise, and neutral.
Emotion-Based Music Recommendations: The detected emotion is mapped to a curated set of music genres or tracks that best correspond to the mood, offering personalized and adaptive recommendations.
Customizable Music Library: Users can upload their own playlists or integrate with music streaming APIs (like Spotify or YouTube) for a seamless music recommendation experience.
Machine Learning Integration: The system is powered by pre-trained deep learning models such as OpenCV and TensorFlow/Keras for facial expression recognition, and custom recommendation algorithms for music selection.

Technologies Used:
Python: The core programming language for implementing the recommendation system and facial expression analysis.
OpenCV: Used for real-time facial detection and image processing.
TensorFlow/Keras: For building and deploying emotion detection models.
Spotify API / YouTube API: Integration for accessing music tracks based on the user's preferences.
Pandas, NumPy: For data processing and handling recommendations.
